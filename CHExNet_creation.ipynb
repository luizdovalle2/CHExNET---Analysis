{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bcac2ef",
   "metadata": {},
   "source": [
    "## First create the time_id dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def half_year_windows(start: date, end: date):\n",
    "    cur = start\n",
    "    while cur <= end:\n",
    "        nxt = cur + relativedelta(months=6)   # step by 6 months [web:277]\n",
    "        yield cur, nxt\n",
    "        cur = nxt\n",
    "lo = date(1350, 1, 1)\n",
    "hi = date(1849, 12, 31)\n",
    "\n",
    "time_id = {}\n",
    "time_dict = {}\n",
    "for t_count, (p_start, p_end) in enumerate(half_year_windows(lo,hi)): \n",
    "    time_id[t_count] = p_start\n",
    "    time_dict[p_start] = t_count\n",
    "\n",
    "import pickle\n",
    "with open(\"time_id_final.pkl\", 'wb') as f:\n",
    "    pickle.dump(time_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac145ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper fucntion for creating adj matrices\n",
    "def adj_from_groups(group_tuples, node_ids, weighted=False, normalize_group=False):\n",
    "    \"\"\"Build sparse adjacency from group co-membership (clique projection).\"\"\"\n",
    "\n",
    "    idx = {pid: i for i, pid in enumerate(node_ids)}\n",
    "    inv_idx = {i: pid for pid, i in idx.items()}\n",
    "\n",
    "    rows, cols, data = [], [], []\n",
    "    acc = {}\n",
    "\n",
    "    for g in group_tuples:\n",
    "        g = [pid for pid in g if pid in idx]\n",
    "        k = len(g)\n",
    "        if k < 2:\n",
    "            continue\n",
    "\n",
    "        w = 1.0 / (k - 1) if normalize_group else 1.0\n",
    "\n",
    "        from itertools import combinations\n",
    "        for a, b in combinations(g, 2):\n",
    "            ia, ib = idx[a], idx[b]\n",
    "            key = (ia, ib) if ia < ib else (ib, ia)\n",
    "            acc[key] = acc.get(key, 0.0) + w\n",
    "\n",
    "    for (ia, ib), w in acc.items():\n",
    "        if not weighted:\n",
    "            w = 1.0\n",
    "        rows += [ia, ib]\n",
    "        cols += [ib, ia]\n",
    "        data += [w, w]\n",
    "\n",
    "    from scipy.sparse import coo_matrix\n",
    "    n = len(node_ids)\n",
    "    W = coo_matrix((data, (rows, cols)), shape=(n, n)).tocsr()\n",
    "    W.setdiag(0)\n",
    "    W.eliminate_zeros()\n",
    "\n",
    "    return W, idx, inv_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b670b10",
   "metadata": {},
   "source": [
    "## load the CAC events and construct layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc32fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pd.read_pickle(\"CAC_matched.pkl\")\n",
    "df_names = pd.read_parquet(\"authority_file_cac_alma.parquet\")\n",
    "df_names_cac = df_names.dropna(subset='cac_id')\n",
    "cac_id_dict = dict(zip(df_names_cac.cac_id.to_list(), df_names_cac.final_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886bf8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}  # out[institution][window_start] = set(person_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897cb6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_col=\"date_start\"\n",
    "end_col=\"date_end\"\n",
    "inst_col=\"event_place_parent_id\"\n",
    "person_col=\"person_id\"\n",
    "\n",
    "d = df_events.copy()\n",
    "\n",
    "\n",
    "d[start_col] = d[start_col].apply(lambda x:x.date())\n",
    "d[end_col] = d[end_col].apply(lambda x:x.date())\n",
    "\n",
    "\n",
    "\n",
    "# half-year window starts: Jan/Jul style (6MS = 6-month starts)\n",
    "win_starts = half_year_windows(d[start_col].min(), d[end_col].max() )\n",
    "\n",
    "for inst, g in d.groupby(inst_col, sort=False):\n",
    "    for ws, we in win_starts:\n",
    "        # interval overlap test: [s,e] overlaps [ws,we] iff s <= we and e >= ws\n",
    "        m = (g[start_col] <= we) & (g[end_col] >= ws)\n",
    "        cur_people = tuple(set(g.loc[m, person_col]))\n",
    "        if len(cur_people) > 1:\n",
    "            cur_people = list(map(lambda x: cac_id_dict[x], cur_people))\n",
    "            output_dict.setdefault(ws, [])\n",
    "            output_dict[ws] += [cur_people]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d32511",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices_layer1 = {}\n",
    "for k, v in output_dict.items():\n",
    "    t_count = time_dict[k]\n",
    "    node_ids = sorted(set(pid for grp in v for pid in grp))\n",
    "    matrix, list_indexes, _ = adj_from_groups(v, node_ids, weighted=False)\n",
    "    matrices_layer1[t_count] = {\n",
    "        \"time\" : k, \n",
    "        \"matrix\" : matrix,\n",
    "        \"ids_pos_mat\" :list_indexes\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288594bd",
   "metadata": {},
   "source": [
    "## Load bibliographic data and create layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9755537",
   "metadata": {},
   "outputs": [],
   "source": [
    "alma_df = pd.read_pickle(\"ALMA_matched.pkl\")\n",
    "df_combined = alma_df[alma_df[\"all_names_final_id\"].apply(lambda x: len(x) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = []\n",
    "matrices_layer2 = {}\n",
    "ids = []\n",
    "for t_count, (p_start, p_end) in enumerate(tqdm(half_year_windows(lo,hi))):\n",
    "    current_match = df_combined[df_combined.apply(lambda row: p_start <= row.date_end and row.date_start <= p_end, axis=1)]['all_names_final_id'].to_list()\n",
    "    if len(current_match)> 0:\n",
    "        node_ids = sorted(set(pid for grp in current_match for pid in grp))\n",
    "        ids.append(node_ids)\n",
    "        matrix, list_indexes, _ = adj_from_groups(current_match, node_ids, weighted=False)\n",
    "        matrices_layer2[t_count] = {\n",
    "            \"time\" : p_start, \n",
    "            \"matrix\" : matrix,\n",
    "            \"ids_pos_mat\" :list_indexes\n",
    "        }\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d3658",
   "metadata": {},
   "source": [
    "## Unite layers and export CHExNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "chexnet = {\"layer_1\":matrices_layer1, \"layer_2\":matrices_layer2}\n",
    "\n",
    "# save\n",
    "with open(\"CHExNet.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chexnet, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
